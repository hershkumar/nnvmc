{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e535440a",
   "metadata": {},
   "source": [
    "# Neural Network Variational Monte Carlo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b48d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"false\"\n",
    "\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"]=\"--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=16 --xla_force_host_platform_device_count={}\".format(multiprocessing.cpu_count())\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=16\"\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax import random, jit, jacfwd, grad, vmap, jvp\n",
    "from jax.nn import one_hot\n",
    "from jax.lax import fori_loop\n",
    "from jax.tree_util import tree_map\n",
    "from flax import linen as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import trange\n",
    "from functools import partial\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import mc # sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aaf29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True energy:  2.0\n"
     ]
    }
   ],
   "source": [
    "bosonic = True\n",
    "if bosonic:\n",
    "    N = 4\n",
    "else:\n",
    "    N_up = 2\n",
    "    N_down = 1\n",
    "# number of pairwise interactions for the delta function sampling\n",
    "if bosonic: \n",
    "        num_interactions = N * (N - 1) // 2\n",
    "else:\n",
    "    num_interactions = N_up * N_down\n",
    "\n",
    "\n",
    "g = 0 # delta coupling\n",
    "omega = 1\n",
    "m = 1\n",
    "harmonic_omega = 1\n",
    "sigma = -m*harmonic_omega*g/2 # long range coupling\n",
    "C = 10 # denominator constant for the symmetrization\n",
    "\n",
    "\n",
    "def astra_energy():\n",
    "    return (N * harmonic_omega)/2 - m * g**2  * (N*(N**2 - 1))/(24)\n",
    "\n",
    "true_energy = astra_energy()\n",
    "\n",
    "print(\"True energy: \", true_energy)\n",
    "# compute a 1% bound for the true energy\n",
    "true_energy_lower = true_energy * 0.99\n",
    "true_energy_upper = true_energy * 1.01\n",
    "\n",
    "total_energy = []\n",
    "total_uncerts = []\n",
    "\n",
    "fig = go.FigureWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e23e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    features: list[int]  # e.g. [64, 64, 1]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for feat in self.features[:-1]:\n",
    "            x = nn.Dense(feat)(x)\n",
    "            x = nn.celu(x)\n",
    "        x = nn.Dense(self.features[-1])(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "@jit\n",
    "def transform(coords):\n",
    "    x = coords / C                                  # (N,)\n",
    "    powers = jnp.cumprod(jnp.broadcast_to(x, (x.shape[0], x.shape[0])), axis=0)\n",
    "    return jnp.sum(powers, axis=1)\n",
    "\n",
    "def create_model(rng_key, N, features):\n",
    "    model = MLP(features=features)\n",
    "    dummy_x = jnp.ones((N,))          # N inputs of length d → shape (N,d)\n",
    "    params = model.init(rng_key, dummy_x)[\"params\"]\n",
    "    return model, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b50e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "    # attributes\n",
      "    features = [50, 100, 100, 100, 100, 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, params = create_model(random.PRNGKey(int(time.time())), N, [50, 100, 100, 100, 100,1])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69561c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jit\n",
    "def A(x, params):\n",
    "    \"\"\"Neural network output, A(x) given a set of parameters\"\"\"\n",
    "    return model.apply({'params': params}, transform(x)).squeeze() + omega * jnp.sum(x**2.)\n",
    "\n",
    "\n",
    "@jit\n",
    "def psi(x, params):\n",
    "    \"\"\"Wavefunction, psi(x) given a set of parameters\"\"\"\n",
    "    return jnp.exp(-A(x, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027d52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs = mc.Sampler(psi, (N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3487a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n",
      "0.7388913\n"
     ]
    }
   ],
   "source": [
    "s,sp, ar = mcs.sample_batched(params, 10000//16, 1000, 3, .3, jnp.zeros((N,)), num_chains=16, key=random.PRNGKey(int(time.time())))\n",
    "print(\"num samples:\", s.shape[0])\n",
    "print(ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcc294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f2e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility functions for pytrees\n",
    "\n",
    "# multiplies a pytree by a scalar elementwise\n",
    "def pytree_scalar_mult(scalar, pytree):\n",
    "    return tree_map(lambda x: scalar * x, pytree)\n",
    "\n",
    "# adds two pytrees elementwise\n",
    "def pytree_add(a, b):\n",
    "    return tree_map(lambda x, y: x + y, a, b)\n",
    "\n",
    "# returns a pytree whos elements are the mean over the first axis of the input pytree elements\n",
    "def tree_mean(pytree_batched):\n",
    "    return tree_map(lambda x: jnp.mean(x, axis=0), pytree_batched)\n",
    "\n",
    "# generates an empty pytree with the same structure as the input pytree\n",
    "def tree_zeros_like(pytree):\n",
    "    return tree_map(jnp.zeros_like, pytree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b63e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1))\n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "grad_psi_x = jit(grad(psi, 0))  # returns (N,)\n",
    "@partial(jit, static_argnames=(\"N\",))\n",
    "def laplacian_psi_jvp(x, params, *, N):\n",
    "    def g(x_):\n",
    "        return grad_psi_x(x_, params)\n",
    "\n",
    "    def body(i, acc):\n",
    "        ei = one_hot(i, N, dtype=x.dtype)\n",
    "        _, dg = jvp(g, (x,), (ei,))\n",
    "        return acc + dg[i]\n",
    "\n",
    "    return fori_loop(0, N, body, jnp.array(0.0, x.dtype))\n",
    "\n",
    "\n",
    "dA_dtheta = jit(grad(A, 1))\n",
    "vdA_dtheta = vmap(dA_dtheta, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "dA_dx = jit(grad(A, 0))\n",
    "vdA_dx = vmap(dA_dx, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "A_hessian = jacfwd(jit(grad(A, 0)), 0)\n",
    "@jit\n",
    "def d2A_dx2(coords, params):\n",
    "    return jnp.diag(A_hessian(coords, params))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def sigma_potential(x):\n",
    "    # pairwise |xi-xj|\n",
    "    diffs = jnp.abs(x[:, None] - x[None, :])         # (N,N)\n",
    "    return sigma * jnp.sum(jnp.triu(diffs, k=1))     # sum_{i<j}\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    return - (1/2) * (1/ psi(coords, params)) * laplacian_psi_jvp(coords, params, N=N) + (1/2) * jnp.sum(coords**2) + sigma_potential(coords)\n",
    "\n",
    "vEs_nodelta = vmap(Es_nodelta, in_axes=(0,None), out_axes=0)\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return num_interactions * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(jnp.sqrt(jnp.pi)*alpha))*jnp.exp(-(coords[-1]/alpha)**2)\n",
    "\n",
    "vEs_delta = vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0)\n",
    "\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return pytree_add(pytree_scalar_mult(2/psi(coords, params) * (es_nodelta - energy_calc), dnn_dtheta(coords, params)), pytree_scalar_mult(2 * es_delta / psi(coords_prime, params), dnn_dtheta(coords_prime, params)))\n",
    "\n",
    "vgradient_comp = vmap(gradient_comp, in_axes=(0, 0, None, 0, None, 0), out_axes=0)\n",
    "\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=(\"chunk_size\",\"g\"))\n",
    "def compute_stats_and_grad(samples, samples_prime, params, g, *, chunk_size=256):\n",
    "    n = samples.shape[0]\n",
    "\n",
    "    # alpha\n",
    "    ys = samples[:, -1]\n",
    "    maxabs = jnp.max(jnp.abs(ys))\n",
    "    alpha = maxabs / jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 1e-10))\n",
    "\n",
    "    # energies\n",
    "    e0 = vEs_nodelta(samples, params)\n",
    "    ed = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "    e = e0 + ed\n",
    "\n",
    "    mean_e = jnp.mean(e)\n",
    "    var_e = jnp.mean(e * e) - mean_e * mean_e\n",
    "    uncert = jnp.sqrt(jnp.maximum(var_e, 0.0)) / jnp.sqrt(n)\n",
    "\n",
    "    # chunks\n",
    "    nb = (n + chunk_size - 1) // chunk_size\n",
    "\n",
    "    grad0 = tree_zeros_like(dnn_dtheta(samples[0], params))\n",
    "\n",
    "    def body(i, grad_sum):\n",
    "        start = i * chunk_size\n",
    "        idx = start + jnp.arange(chunk_size)          # (chunk_size,)\n",
    "        mask = (idx < n).astype(samples.dtype)        # (chunk_size,)\n",
    "\n",
    "        idx = jnp.minimum(idx, n - 1)                 # clamp for safe gather\n",
    "\n",
    "        s_chunk  = samples[idx, :]\n",
    "        sp_chunk = samples_prime[idx, :]\n",
    "        e0_chunk = e0[idx]\n",
    "        ed_chunk = ed[idx]\n",
    "\n",
    "        grads = vgradient_comp(s_chunk, sp_chunk, params, e0_chunk, mean_e, ed_chunk)\n",
    "\n",
    "        # multiply each leaf by mask on leading axis, then sum over axis 0\n",
    "        def masked_sum(x):\n",
    "            # x has leading dimension chunk_size\n",
    "            reshape = (chunk_size,) + (1,) * (x.ndim - 1)\n",
    "            return jnp.sum(x * mask.reshape(reshape), axis=0)\n",
    "\n",
    "        grads_sum = tree_map(masked_sum, grads)\n",
    "        return pytree_add(grad_sum, grads_sum)\n",
    "\n",
    "    grad_sum = fori_loop(0, nb, body, grad0)\n",
    "    mean_grad = pytree_scalar_mult(1.0 / n, grad_sum)\n",
    "\n",
    "    return mean_grad, mean_e, uncert\n",
    "\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=5, variation_size=1.0, sampling=\"serial\", chunk_size=256):\n",
    "    if sampling == \"serial\":\n",
    "        samples, samples_prime, _ = mcs.sample(params, num_samples, thermal, skip, variation_size, jnp.zeros((N,)))\n",
    "    elif sampling == \"parallel\":\n",
    "        n_chains = 16\n",
    "        samples, samples_prime, _ = mcs.sample_batched(params, num_samples//n_chains, thermal, skip, variation_size, jnp.zeros((N,)), num_chains=n_chains, key=random.PRNGKey(int(time.time())))\n",
    "\n",
    "    return compute_stats_and_grad(samples, samples_prime, params, g, chunk_size=chunk_size)\n",
    "\n",
    "\n",
    "def step(params, opt_state, step_num, num_samples, thermal, skip, variation_size, g, sampling, chunk_size):\n",
    "    \"\"\"\n",
    "    One optimization step.\n",
    "    - params: current parameters pytree\n",
    "    - opt_state: optimizer state (must be carried across steps)\n",
    "    Returns: (new_params, new_opt_state, energy, uncert)\n",
    "    \"\"\"\n",
    "    grad, energy, uncert = gradient(\n",
    "        params,\n",
    "        g,\n",
    "        num_samples=num_samples,\n",
    "        thermal=thermal,\n",
    "        skip=skip,\n",
    "        variation_size=variation_size,\n",
    "        sampling=sampling,\n",
    "        chunk_size=chunk_size,\n",
    "    )\n",
    "    new_opt_state = opt_update(step_num, grad, opt_state)\n",
    "    new_params = get_params(new_opt_state)\n",
    "\n",
    "    return new_params, new_opt_state, energy, uncert\n",
    "\n",
    "def update_plot(total_energy, total_uncerts):\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].x = np.arange(len(total_energy))\n",
    "        fig.data[0].y = total_energy\n",
    "        fig.data[0].error_y.array = total_uncerts\n",
    "\n",
    "        n = len(total_energy)\n",
    "        for i in [1, 2, 3]:\n",
    "            fig.data[i].x = [0, n]\n",
    "              \n",
    "\n",
    "def train(params, iterations, num_samples, thermal, skip, variation_size, g, sampling=\"serial\", chunk_size=256, energy_storage=total_energy, uncert_storage=total_uncerts):\n",
    "    \"\"\"\n",
    "    Training loop.\n",
    "    Returns: (hs, us, ns, final_params)\n",
    "    \"\"\"\n",
    "    hs, us = [], []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    # Initialize optimizer state ONCE\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "    old_params = params\n",
    "\n",
    "    for step_num in pbar:\n",
    "        new_params, opt_state, energy, uncert = step(\n",
    "            old_params,\n",
    "            opt_state,\n",
    "            step_num,\n",
    "            num_samples,\n",
    "            thermal,\n",
    "            skip,\n",
    "            variation_size,\n",
    "            g,\n",
    "            sampling=sampling,\n",
    "            chunk_size=chunk_size,\n",
    "        )\n",
    "        \n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params\n",
    "\n",
    "        energy_storage.append(energy)\n",
    "        uncert_storage.append(uncert)\n",
    "        update_plot(energy_storage, uncert_storage)\n",
    "\n",
    "        pbar.set_description(f\"Energy = {energy}\", refresh=True)\n",
    "\n",
    "        # Use jnp.isnan if energy is a JAX scalar; np.isnan is OK if it's a Python float\n",
    "        if np.isnan(np.asarray(energy)):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            #TODO: backtrack to previous params, try again?\n",
    "            break\n",
    "\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9183a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d585b4959c4cd899e45f4764a342fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'error_y': {'array': [], 'type': 'data', 'visible': True},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Energy vs Iteration',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'be5b36a2-c201-448c-8ad5-33ecda2c784a',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'red', 'dash': 'dash'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy',\n",
       "              'type': 'scatter',\n",
       "              'uid': '12200d6d-5848-45f2-8683-c664b33f41d7',\n",
       "              'x': [0, 0],\n",
       "              'y': [2.0, 2.0]},\n",
       "             {'line': {'color': 'green', 'dash': 'dot'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy Lower Bound',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3fa2ac10-39d9-43b7-aa60-251835b5b613',\n",
       "              'x': [0, 0],\n",
       "              'y': [1.98, 1.98]},\n",
       "             {'line': {'color': 'green', 'dash': 'dot'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy Upper Bound',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ee493217-f1ab-4c2c-9ee0-86e3842e8bc6',\n",
       "              'x': [0, 0],\n",
       "              'y': [2.02, 2.02]}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'VMC Energy Convergence'},\n",
       "               'xaxis': {'title': {'text': 'Iteration'}},\n",
       "               'yaxis': {'title': {'text': 'Energy'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "energy_trace = fig.add_scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    error_y=dict(type='data', array=[], visible=True),\n",
    "    mode='lines+markers',\n",
    "    name='Energy vs Iteration'\n",
    ")\n",
    "\n",
    "\n",
    "# add a horizontal line for the true energy\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy, true_energy],\n",
    "    mode='lines',\n",
    "    name='True Energy',\n",
    "    line=dict(dash='dash', color='red')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy_lower, true_energy_lower],\n",
    "    mode='lines',\n",
    "    name='True Energy Lower Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy_upper, true_energy_upper],\n",
    "    mode='lines',\n",
    "    name='True Energy Upper Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='VMC Energy Convergence',\n",
    "    xaxis_title='Iteration',\n",
    "    yaxis_title='Energy',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.9953316450119019:  26%|██▌       | 102/400 [00:32<01:35,  3.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m opt_init, opt_update, get_params = jax_opt.adam(\u001b[32m10\u001b[39m ** (-\u001b[32m3\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# params, N_steps, N_samples, thermalization, skip, variation_size, g, sampling_type, gradient chunk size\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m resultsa = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 173\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, iterations, num_samples, thermal, skip, variation_size, g, sampling, chunk_size, energy_storage, uncert_storage)\u001b[39m\n\u001b[32m    170\u001b[39m old_params = params\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step_num \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     new_params, opt_state, energy, uncert = \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mold_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthermal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariation_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     hs.append(energy)\n\u001b[32m    188\u001b[39m     us.append(uncert)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mstep\u001b[39m\u001b[34m(params, opt_state, step_num, num_samples, thermal, skip, variation_size, g, sampling, chunk_size)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03mOne optimization step.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m- params: current parameters pytree\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m- opt_state: optimizer state (must be carried across steps)\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03mReturns: (new_params, new_opt_state, energy, uncert)\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m grad, energy, uncert = gradient(\n\u001b[32m    133\u001b[39m     params,\n\u001b[32m    134\u001b[39m     g,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m     chunk_size=chunk_size,\n\u001b[32m    141\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m new_opt_state = \u001b[43mopt_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m new_params = get_params(new_opt_state)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_params, new_opt_state, energy, uncert\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/nnvmc/.venv/lib/python3.13/site-packages/jax/example_libraries/optimizers.py:197\u001b[39m, in \u001b[36moptimizer.<locals>.tree_opt_maker.<locals>.tree_update\u001b[39m\u001b[34m(i, grad_tree, opt_state)\u001b[39m\n\u001b[32m    195\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(tree, tree2))\n\u001b[32m    196\u001b[39m states = \u001b[38;5;28mmap\u001b[39m(jax.tree.unflatten, subtrees, states_flat)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m new_states = \u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m new_states_flat, subtrees2 = unzip2(\u001b[38;5;28mmap\u001b[39m(jax.tree.flatten, new_states))\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m subtree, subtree2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(subtrees, subtrees2):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/nnvmc/.venv/lib/python3.13/site-packages/jax/example_libraries/optimizers.py:420\u001b[39m, in \u001b[36madam.<locals>.update\u001b[39m\u001b[34m(i, g, state)\u001b[39m\n\u001b[32m    418\u001b[39m mhat = m / (\u001b[32m1\u001b[39m - jnp.asarray(b1, m.dtype) ** (i + \u001b[32m1\u001b[39m))  \u001b[38;5;66;03m# Bias correction.\u001b[39;00m\n\u001b[32m    419\u001b[39m vhat = v / (\u001b[32m1\u001b[39m - jnp.asarray(b2, m.dtype) ** (i + \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m x = x - \u001b[43mstep_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mmhat\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvhat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, m, v\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/nnvmc/.venv/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py:609\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    607\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "# params, N_steps, N_samples, thermalization, skip, variation_size, g, sampling_type, gradient chunk size\n",
    "resultsa = train(params, 100, 10000, 500, 2, 0.3, g, sampling=\"parallel\", chunk_size=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-4))\n",
    "\n",
    "resultsb = train(resultsa[3], 100, 20000, 1000, 4, 0.3, g, sampling=\"parallel\", chunk_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72efd046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnvmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
