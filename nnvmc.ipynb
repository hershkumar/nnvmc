{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e535440a",
   "metadata": {},
   "source": [
    "# Neural Network Variational Monte Carlo\n",
    "\n",
    "1 Dimensional, N bosons or N_up and N_down fermions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b48d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "os.environ[\"JAX_ENABLE_X64\"]=\"false\"\n",
    "\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"]=\"--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=16 --xla_force_host_platform_device_count={}\".format(multiprocessing.cpu_count())\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=16\"\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax import random, jit, jacfwd, grad, vmap, jvp\n",
    "from jax.nn import one_hot\n",
    "from jax.lax import fori_loop\n",
    "from jax.tree_util import tree_map\n",
    "from flax import linen as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import trange\n",
    "from functools import partial\n",
    "import jax.example_libraries.optimizers as jax_opt\n",
    "import plotly.graph_objects as go\n",
    "import mc # sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aaf29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True energy:  1.6999999999999997\n"
     ]
    }
   ],
   "source": [
    "bosonic = True\n",
    "if bosonic:\n",
    "    N = 5\n",
    "else:\n",
    "    N_up = 2\n",
    "    N_down = 1\n",
    "\n",
    "g = .4\n",
    "omega = 1\n",
    "m = 1\n",
    "harmonic_omega = 1\n",
    "sigma = -m*harmonic_omega*g/2\n",
    "C = 10\n",
    "\n",
    "\n",
    "def astra_energy():\n",
    "    return (N * harmonic_omega)/2 - m * g**2  * (N*(N**2 - 1))/(24)\n",
    "\n",
    "true_energy = astra_energy()\n",
    "\n",
    "# true_energy = .5 * N\n",
    "\n",
    "print(\"True energy: \", true_energy)\n",
    "# compute a 1% bound for the true energy\n",
    "true_energy_lower = true_energy * 0.99\n",
    "true_energy_upper = true_energy * 1.01\n",
    "\n",
    "\n",
    "\n",
    "total_energy = []\n",
    "total_uncerts = []\n",
    "\n",
    "fig = go.FigureWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44e23e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    features: list[int]  # e.g. [64, 64, 1]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for feat in self.features[:-1]:\n",
    "            x = nn.Dense(feat)(x)\n",
    "            x = nn.celu(x)\n",
    "        x = nn.Dense(self.features[-1])(x)\n",
    "        return x\n",
    "\n",
    "from typing import Sequence, Callable, Optional\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    features: Sequence[int]          # hidden widths, e.g. [128, 128, 128]\n",
    "    out_dim: int = 1\n",
    "    act: Callable = nn.celu\n",
    "    dropout: float = 0.0\n",
    "    use_layernorm: bool = True\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, *, train: bool = False):\n",
    "        # x: (N,) or (batch, N)\n",
    "        h = x\n",
    "        for w in self.features:\n",
    "            y = nn.Dense(w)(h)\n",
    "            if self.use_layernorm:\n",
    "                y = nn.LayerNorm()(y)\n",
    "            y = self.act(y)\n",
    "            if self.dropout > 0:\n",
    "                y = nn.Dropout(self.dropout)(y, deterministic=not train)\n",
    "\n",
    "            y = nn.Dense(w)(y)  # second linear in the block\n",
    "            if self.use_layernorm:\n",
    "                y = nn.LayerNorm()(y)\n",
    "\n",
    "            # residual connection (project if needed)\n",
    "            if h.shape[-1] != w:\n",
    "                h = nn.Dense(w)(h)\n",
    "            h = self.act(h + y)\n",
    "\n",
    "        return nn.Dense(self.out_dim)(h).squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def transform(coords):\n",
    "    x = coords / C                                  # (N,)\n",
    "    powers = jnp.cumprod(jnp.broadcast_to(x, (x.shape[0], x.shape[0])), axis=0)\n",
    "    return jnp.sum(powers, axis=1)\n",
    "\n",
    "def create_model(rng_key, N, features):\n",
    "    model = MLP(features=features)\n",
    "    # model = ResidualMLP(features=features[:-1], out_dim=features[-1], dropout=0.0, use_layernorm=False)\n",
    "    dummy_x = jnp.ones((N,))          # N inputs of length d → shape (N,d)\n",
    "    params = model.init(rng_key, dummy_x)[\"params\"]\n",
    "    return model, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b50e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "    # attributes\n",
      "    features = [50, 100, 100, 100, 100, 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, params = create_model(random.PRNGKey(int(time.time())), N, [50, 100, 100, 100, 100,1])\n",
    "print(model)\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69561c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0073917126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@jit\n",
    "def A(x, params):\n",
    "    \"\"\"Neural network output, A(x) given a set of parameters\"\"\"\n",
    "    return model.apply({'params': params}, transform(x)).squeeze() + omega * jnp.sum(x**2.)\n",
    "\n",
    "\n",
    "@jit\n",
    "def psi(x, params):\n",
    "    \"\"\"Wavefunction, psi(x) given a set of parameters\"\"\"\n",
    "    return jnp.exp(-A(x, params))\n",
    "\n",
    "\n",
    "print(psi(jnp.ones((N,)), params)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "027d52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs = mc.Sampler(psi, (N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a737edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s,sp, ar = mcs.sample_parallel(params, 1000000//16, 1000, 3, .7, jnp.zeros((N,)), num_chains=16)\n",
    "# print(\"num samples:\", s.shape[0])\n",
    "# print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3487a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n",
      "0.70739126\n",
      "[-0.4534186   0.4511728   0.14964408  0.47998768 -0.13952422]\n",
      "[-0.4534186   0.4511728   0.14964408  0.47998768 -0.4534186 ]\n",
      "[-0.4534186  -0.5534365  -0.27984267 ...  0.07559907  0.07061088\n",
      " -0.10250926]\n",
      "[-0.4534186  -0.5534365  -0.27984267 ...  0.07559907  0.07061088\n",
      " -0.10250926]\n"
     ]
    }
   ],
   "source": [
    "s,sp, ar = mcs.sample_batched(params, 10000//16, 1000, 3, .3, jnp.zeros((N,)), num_chains=16, key=random.PRNGKey(int(time.time())))\n",
    "print(\"num samples:\", s.shape[0])\n",
    "print(ar)\n",
    "print(s[0])\n",
    "print(sp[0])\n",
    "print(s[:,0])\n",
    "print(sp[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcc294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2e9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b63e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of the wavefunction with respect to the parameters\n",
    "dnn_dtheta = jit(grad(psi, 1))\n",
    "vdnn_dtheta = jit(vmap(dnn_dtheta, in_axes=(0, None), out_axes=0))\n",
    "\n",
    "\n",
    "\n",
    "grad_psi_x = jit(grad(psi, 0))  # returns (N,)\n",
    "@partial(jit, static_argnames=(\"N\",))\n",
    "def laplacian_psi_jvp(x, params, *, N):\n",
    "    def g(x_):\n",
    "        return grad_psi_x(x_, params)\n",
    "\n",
    "    def body(i, acc):\n",
    "        ei = one_hot(i, N, dtype=x.dtype)\n",
    "        _, dg = jvp(g, (x,), (ei,))\n",
    "        return acc + dg[i]\n",
    "\n",
    "    return fori_loop(0, N, body, jnp.array(0.0, x.dtype))\n",
    "\n",
    "\n",
    "\n",
    "if bosonic: \n",
    "        num_interactions = N * (N - 1) // 2\n",
    "else:\n",
    "    num_interactions = N_up * N_down\n",
    "\n",
    "dA_dtheta = jit(grad(A, 1))\n",
    "vdA_dtheta = vmap(dA_dtheta, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "dA_dx = jit(grad(A, 0))\n",
    "vdA_dx = vmap(dA_dx, in_axes=(0, None), out_axes=0)\n",
    "\n",
    "A_hessian = jacfwd(jit(grad(A, 0)), 0)\n",
    "@jit\n",
    "def d2A_dx2(coords, params):\n",
    "    return jnp.diag(A_hessian(coords, params))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def sigma_potential(x):\n",
    "    # pairwise |xi-xj|\n",
    "    diffs = jnp.abs(x[:, None] - x[None, :])         # (N,N)\n",
    "    return sigma * jnp.sum(jnp.triu(diffs, k=1))     # sum_{i<j}\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_nodelta(coords, params):\n",
    "    # return - (1/2) * (1/ psi(coords, params)) * jnp.sum(ddpsi(coords, params)) + (1/2) * jnp.sum(coords**2) \n",
    "    return - (1/2) * (1/ psi(coords, params)) * laplacian_psi_jvp(coords, params, N=N) + (1/2) * jnp.sum(coords**2) + sigma_potential(coords)\n",
    "    # return (1/2) * (jnp.sum(d2A_dx2(coords, params)) - jnp.sum(dA_dx(coords, params)**2)) + (1/2) * jnp.sum(coords**2)  + sigma_potential(coords)\n",
    "\n",
    "vEs_nodelta = vmap(Es_nodelta, in_axes=(0,None), out_axes=0)\n",
    "\n",
    "\n",
    "@jit\n",
    "def Es_delta(coords, coords_prime, params, alpha, g):\n",
    "    return num_interactions * g * (psi(coords_prime, params)**2)/(psi(coords, params)**2) * (1/(jnp.sqrt(jnp.pi)*alpha))*jnp.exp(-(coords[-1]/alpha)**2)\n",
    "\n",
    "vEs_delta = vmap(Es_delta, in_axes=(0,0, None, None, None), out_axes=0)\n",
    "\n",
    "def pytree_scalar_mult(scalar, pytree):\n",
    "    return tree_map(lambda x: scalar * x, pytree)\n",
    "\n",
    "def pytree_add(a, b):\n",
    "    return tree_map(lambda x, y: x + y, a, b)\n",
    "\n",
    "@jit\n",
    "def tree_mean(pytree_batched):\n",
    "    return tree_map(lambda x: jnp.mean(x, axis=0), pytree_batched)\n",
    "\n",
    "def tree_zeros_like(pytree):\n",
    "    return tree_map(jnp.zeros_like, pytree)\n",
    "\n",
    "\n",
    "@jit\n",
    "def gradient_comp(coords, coords_prime, params, es_nodelta, energy_calc, es_delta):\n",
    "    return pytree_add(pytree_scalar_mult(2/psi(coords, params) * (es_nodelta - energy_calc), dnn_dtheta(coords, params)), pytree_scalar_mult(2 * es_delta / psi(coords_prime, params), dnn_dtheta(coords_prime, params)))\n",
    "\n",
    "vgradient_comp = vmap(gradient_comp, in_axes=(0, 0, None, 0, None, 0), out_axes=0)\n",
    "\n",
    "\n",
    "\n",
    "@partial(jit, static_argnames=(\"chunk_size\",\"g\"))\n",
    "def compute_stats_and_grad(samples, samples_prime, params, g, *, chunk_size=256):\n",
    "    n = samples.shape[0]\n",
    "\n",
    "    # alpha\n",
    "    ys = samples[:, -1]\n",
    "    maxabs = jnp.max(jnp.abs(ys))\n",
    "    alpha = maxabs / jnp.sqrt(-jnp.log(jnp.sqrt(jnp.pi) * 1e-10))\n",
    "\n",
    "    # energies\n",
    "    e0 = vEs_nodelta(samples, params)\n",
    "    ed = vEs_delta(samples, samples_prime, params, alpha, g)\n",
    "    e = e0 + ed\n",
    "\n",
    "    mean_e = jnp.mean(e)\n",
    "    var_e = jnp.mean(e * e) - mean_e * mean_e\n",
    "    uncert = jnp.sqrt(jnp.maximum(var_e, 0.0)) / jnp.sqrt(n)\n",
    "\n",
    "    # chunks\n",
    "    nb = (n + chunk_size - 1) // chunk_size\n",
    "\n",
    "    grad0 = tree_zeros_like(dnn_dtheta(samples[0], params))\n",
    "\n",
    "    def body(i, grad_sum):\n",
    "        start = i * chunk_size\n",
    "        idx = start + jnp.arange(chunk_size)          # (chunk_size,)\n",
    "        mask = (idx < n).astype(samples.dtype)        # (chunk_size,)\n",
    "\n",
    "        idx = jnp.minimum(idx, n - 1)                 # clamp for safe gather\n",
    "\n",
    "        s_chunk  = samples[idx, :]\n",
    "        sp_chunk = samples_prime[idx, :]\n",
    "        e0_chunk = e0[idx]\n",
    "        ed_chunk = ed[idx]\n",
    "\n",
    "        grads = vgradient_comp(s_chunk, sp_chunk, params, e0_chunk, mean_e, ed_chunk)\n",
    "\n",
    "        # multiply each leaf by mask on leading axis, then sum over axis 0\n",
    "        def masked_sum(x):\n",
    "            # x has leading dimension chunk_size\n",
    "            reshape = (chunk_size,) + (1,) * (x.ndim - 1)\n",
    "            return jnp.sum(x * mask.reshape(reshape), axis=0)\n",
    "\n",
    "        grads_sum = tree_map(masked_sum, grads)\n",
    "        return pytree_add(grad_sum, grads_sum)\n",
    "\n",
    "    grad_sum = fori_loop(0, nb, body, grad0)\n",
    "    mean_grad = pytree_scalar_mult(1.0 / n, grad_sum)\n",
    "\n",
    "    return mean_grad, mean_e, uncert\n",
    "\n",
    "\n",
    "def gradient(params, g, num_samples=10**3, thermal=200, skip=5, variation_size=1.0, sampling=\"serial\", chunk_size=256):\n",
    "    if sampling == \"serial\":\n",
    "        samples, samples_prime, _ = mcs.sample(params, num_samples, thermal, skip, variation_size, jnp.zeros((N,)))\n",
    "    elif sampling == \"parallel\":\n",
    "        n_chains = 16\n",
    "        samples, samples_prime, _ = mcs.sample_batched(params, num_samples//n_chains, thermal, skip, variation_size, jnp.zeros((N,)), num_chains=n_chains, key=random.PRNGKey(int(time.time())))\n",
    "\n",
    "    return compute_stats_and_grad(samples, samples_prime, params, g, chunk_size=chunk_size)\n",
    "\n",
    "\n",
    "def step(params, opt_state, step_num, num_samples, thermal, skip, variation_size, g, sampling, chunk_size):\n",
    "    \"\"\"\n",
    "    One optimization step.\n",
    "    - params: current parameters pytree\n",
    "    - opt_state: optimizer state (must be carried across steps)\n",
    "    Returns: (new_params, new_opt_state, energy, uncert)\n",
    "    \"\"\"\n",
    "    grad, energy, uncert = gradient(\n",
    "        params,\n",
    "        g,\n",
    "        num_samples=num_samples,\n",
    "        thermal=thermal,\n",
    "        skip=skip,\n",
    "        variation_size=variation_size,\n",
    "        sampling=sampling,\n",
    "        chunk_size=chunk_size,\n",
    "    )\n",
    "    new_opt_state = opt_update(step_num, grad, opt_state)\n",
    "    new_params = get_params(new_opt_state)\n",
    "\n",
    "    return new_params, new_opt_state, energy, uncert\n",
    "\n",
    "def update_plot(total_energy, total_uncerts):\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].x = np.arange(len(total_energy))\n",
    "        fig.data[0].y = total_energy\n",
    "        fig.data[0].error_y.array = total_uncerts\n",
    "\n",
    "        n = len(total_energy)\n",
    "        for i in [1, 2, 3]:\n",
    "            fig.data[i].x = [0, n]\n",
    "              \n",
    "\n",
    "def train(params, iterations, num_samples, thermal, skip, variation_size, g, sampling=\"serial\", chunk_size=256, energy_storage=total_energy, uncert_storage=total_uncerts):\n",
    "    \"\"\"\n",
    "    Training loop.\n",
    "    Returns: (hs, us, ns, final_params)\n",
    "    \"\"\"\n",
    "    hs, us = [], []\n",
    "    ns = np.arange(iterations)\n",
    "\n",
    "    # Initialize optimizer state ONCE\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    pbar = trange(iterations, desc=\"\", leave=True)\n",
    "    old_params = params\n",
    "\n",
    "    for step_num in pbar:\n",
    "        new_params, opt_state, energy, uncert = step(\n",
    "            old_params,\n",
    "            opt_state,\n",
    "            step_num,\n",
    "            num_samples,\n",
    "            thermal,\n",
    "            skip,\n",
    "            variation_size,\n",
    "            g,\n",
    "            sampling=sampling,\n",
    "            chunk_size=chunk_size,\n",
    "        )\n",
    "        \n",
    "\n",
    "        hs.append(energy)\n",
    "        us.append(uncert)\n",
    "        old_params = new_params\n",
    "\n",
    "        energy_storage.append(energy)\n",
    "        uncert_storage.append(uncert)\n",
    "        update_plot(energy_storage, uncert_storage)\n",
    "\n",
    "        pbar.set_description(f\"Energy = {energy}\", refresh=True)\n",
    "\n",
    "        # Use jnp.isnan if energy is a JAX scalar; np.isnan is OK if it's a Python float\n",
    "        if np.isnan(np.asarray(energy)):\n",
    "            print(\"NaN encountered, stopping...\")\n",
    "            #TODO: backtrack to previous params, try again?\n",
    "            break\n",
    "\n",
    "    return hs, us, ns, old_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9183a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a24f44db9e4c2a857698fe9717df89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'error_y': {'array': [], 'type': 'data', 'visible': True},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Energy vs Iteration',\n",
       "              'type': 'scatter',\n",
       "              'uid': '2f105044-7209-4fda-8a34-f272cd1d6eae',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'red', 'dash': 'dash'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'a54586e8-8949-4aff-a3ed-5a00ee9b271d',\n",
       "              'x': [0, 0],\n",
       "              'y': [1.6999999999999997, 1.6999999999999997]},\n",
       "             {'line': {'color': 'green', 'dash': 'dot'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy Lower Bound',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6b73fba4-2c8b-4764-9c8a-61ced353654b',\n",
       "              'x': [0, 0],\n",
       "              'y': [1.6829999999999998, 1.6829999999999998]},\n",
       "             {'line': {'color': 'green', 'dash': 'dot'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'True Energy Upper Bound',\n",
       "              'type': 'scatter',\n",
       "              'uid': '18d42e97-93a6-45ec-a6aa-0ae8d1ad814e',\n",
       "              'x': [0, 0],\n",
       "              'y': [1.7169999999999996, 1.7169999999999996]}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'VMC Energy Convergence'},\n",
       "               'xaxis': {'title': {'text': 'Iteration'}},\n",
       "               'yaxis': {'title': {'text': 'Energy'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "energy_trace = fig.add_scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    error_y=dict(type='data', array=[], visible=True),\n",
    "    mode='lines+markers',\n",
    "    name='Energy vs Iteration'\n",
    ")\n",
    "\n",
    "\n",
    "# add a horizontal line for the true energy\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy, true_energy],\n",
    "    mode='lines',\n",
    "    name='True Energy',\n",
    "    line=dict(dash='dash', color='red')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy_lower, true_energy_lower],\n",
    "    mode='lines',\n",
    "    name='True Energy Lower Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(total_energy)],\n",
    "    y=[true_energy_upper, true_energy_upper],\n",
    "    mode='lines',\n",
    "    name='True Energy Upper Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='VMC Energy Convergence',\n",
    "    xaxis_title='Iteration',\n",
    "    yaxis_title='Energy',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffc1307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.8311909437179565: 100%|██████████| 400/400 [03:12<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-3))\n",
    "# params, N_steps, N_samples, thermalization, skip, variation_size, g, sampling_type, gradient chunk size\n",
    "resultsa = train(params, 400, 20000, 500, 2, 0.3, g, sampling=\"parallel\", chunk_size=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a72b9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy = 1.7719908952713013: 100%|██████████| 100/100 [02:02<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "opt_init, opt_update, get_params = jax_opt.adam(10 ** (-4))\n",
    "\n",
    "resultsb = train(resultsa[3], 100, 50000, 1000, 4, 0.3, g, sampling=\"parallel\", chunk_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsc = train(resultsb[3], 200, 100000, 1000, 2, 0.7, g, sampling=\"parallel\", chunk_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac94cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_init, opt_update, get_params = jax_opt.adam(10 ** (-4))\n",
    "\n",
    "resultsd = train(resultsc[3], 200, 100000, 2000, 3, 0.7, g, sampling=\"parallel\", chunk_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b578c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resultsa[0] + resultsb[0] + resultsc[0] + resultsd[0]\n",
    "res_uncerts = resultsa[1] + resultsb[1] + resultsc[1] + resultsd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(res)),\n",
    "    y=res,\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=res_uncerts,\n",
    "        visible=True\n",
    "    ),\n",
    "    mode='lines+markers',\n",
    "    name='Energy vs Iteration'\n",
    "))\n",
    "\n",
    "# add a horizontal line for the true energy\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(res)],\n",
    "    y=[true_energy, true_energy],\n",
    "    mode='lines',\n",
    "    name='True Energy',\n",
    "    line=dict(dash='dash', color='red')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(res)],\n",
    "    y=[true_energy_lower, true_energy_lower],\n",
    "    mode='lines',\n",
    "    name='True Energy Lower Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, len(res)],\n",
    "    y=[true_energy_upper, true_energy_upper],\n",
    "    mode='lines',\n",
    "    name='True Energy Upper Bound',\n",
    "    line=dict(dash='dot', color='green')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='VMC Energy Convergence',\n",
    "    xaxis_title='Iteration Number',\n",
    "    yaxis_title='Energy',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = jnp.array([1.0, 2.0, 4.0])\n",
    "test2 = jnp.array([2.0, 1.0, 4.0])\n",
    "print(psi(test, params))\n",
    "print(psi(test2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a6153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ef81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, samples_prime, ar = mcs.sample_batched(resultsa[3], 1000000//16, 1000, 3, .7, jnp.zeros((N,)), num_chains=16, key=random.PRNGKey(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the samples for each particle\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(N):\n",
    "    plt.figure()\n",
    "    plt.hist(samples_prime[:, i], bins=100, density=True)\n",
    "    plt.title(f'Histogram of samples for particle {i+1}')\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e2b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnvmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
